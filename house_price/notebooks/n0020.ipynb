{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer to:\n",
    "https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "\n",
    "#from subprocess import check_output\n",
    "##print(check_output(['ls', '../input']).decode('utf8'))\n",
    "#print(check_output(['ls', '..']).decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for p in '*', '../*', '../input/*':\n",
    "  print(p, end=' ')\n",
    "  print(glob.glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train.shape', train.shape, 'test.shape', test.shape)\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)\n",
    "print('train.shape', train.shape, 'test.shape', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x=train['GrLivArea'], y=train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\n",
    " train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)]\n",
    " .index )\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(train['GrLivArea'], train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['SalePrice'], fit=norm);\n",
    "mu, sigma = norm.fit(train['SalePrice'])\n",
    "print('\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "           loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SalePrice'] = np.log1p(train['SalePrice'])\n",
    "sns.distplot(train['SalePrice'], fit=norm);\n",
    "mu, sigma = norm.fit(train['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "plt.legend(\n",
    " ['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    " loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.SalePrice.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = (all_data.isnull().sum() / len(all_data))*100\n",
    "#all_data_na = (\n",
    "#  all_data_na.drop(all_data_na[all_data_na == 0].index)\n",
    "#  .sort_values(ascending=False)[:30] )\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index) \\\n",
    " .sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=all_data_na.index, y=all_data_na)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Percent of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train.corr()\n",
    "plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['PoolQC'] = all_data['PoolQC'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['MiscFeature'] = all_data['MiscFeature'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Alley'] = all_data['Alley'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Fence'] = all_data['Fence'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['FireplaceQu'] = all_data['FireplaceQu'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'] \\\n",
    " .transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond':\n",
    "    all_data[col] = all_data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'GarageYrBlt', 'GarageArea', 'GarageCars':\n",
    "    all_data[col] = all_data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \\\n",
    " 'BsmtFullBath', 'BsmtHalfBath':\n",
    "    all_data[col] = all_data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \\\n",
    " 'BsmtFinType2':\n",
    "    all_data[col] = all_data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['MasVnrType'] = all_data['MasVnrType'].fillna('None')\n",
    "all_data['MasVnrArea'] = all_data['MasVnrArea'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Functional'] = all_data['Functional'].fillna('Typ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['MSSubClass'] = all_data['MSSubClass'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = (all_data.isnull().sum() / len(all_data))*100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index) \\\n",
    " .sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
    "all_data['MoSold'] = all_data['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond',\n",
    " 'ExterQual', 'ExterCond', 'HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1',\n",
    " 'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    " 'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond',\n",
    " 'YrSold', 'MoSold')\n",
    "\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(all_data[c].values))\n",
    "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "\n",
    "print('Shape all_data: {}'.format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != 'object'].index\n",
    "#all_data.dtypes != 'object'\n",
    "#all_data.index\n",
    "#all_data.dtypes.index\n",
    "#numeric_feats\n",
    "#all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "#all_data.loc[:, 0:2]\n",
    "#all_data.loc[0:4, '1stFlrSF':'2ndFlrSF'].apply(lambda x: skew(x))\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())) \\\n",
    " .sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print('There are {} skewed numerical features to Box Cox transform'\n",
    " .format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse = np.sqrt(\n",
    "     -cross_val_score(\n",
    "      model, train.values, y_train, scoring='neg_mean_squared_error',\n",
    "      cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha = 0.0005, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet = make_pipeline(\n",
    " RobustScaler(),\n",
    " ElasticNet(alpha=0.005, l1_ratio=.9, random_state=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor \\\n",
    " ( n_estimators=300, learning_rate=0.05, max_depth=4, max_features='sqrt'\n",
    " , min_samples_leaf=15, min_samples_split=10, loss='huber', random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor \\\n",
    " ( colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05, max_depth=3\n",
    " , min_child_weight=1.7817, n_estimators=2200, reg_alpha=0.4640\n",
    " , reg_lambda=0.8571, subsample=0.5213, silent=1, random_state=7, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor \\\n",
    " ( objective='regression', num_leaves=5, learning_rate=0.05, n_estimators=720\n",
    " , max_bin=55, bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2319\n",
    " , feature_fraction_seed=9, bagging_seed=9, min_data_in_leaf=6\n",
    " , min_sum_hessian_in_leaf=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"Lasso score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "  def __init__(self, models):\n",
    "    self.models = models\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    self.models_ = [clone(x) for x in self.models]\n",
    "    for model in self.models_:\n",
    "      model.fit(X, y)\n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    predictions = np.column_stack \\\n",
    "     ([model.predict(X) for model in self.models_])\n",
    "    return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_model = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n",
    "score = rmsle_cv(averaged_model)\n",
    "print(\"Averaged base models score: {:.4f} ({:.4f})\"\n",
    " .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12345678901234567890123456789012345678901234567890123456789012345678901234567890\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "  def __init__(self, base_models, meta_model, n_folds=5):\n",
    "    self.base_models = base_models\n",
    "    self.meta_model = meta_model\n",
    "    self.n_folds = n_folds\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    self.base_models_ = [list() for x in self.base_models]\n",
    "    self.meta_model_ = clone(self.meta_model)\n",
    "    kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "    out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "    for i, model in enumerate(self.base_models):\n",
    "      for train_index, holdout_index in kfold.split(X, y):\n",
    "        instance = clone(model)\n",
    "        self.base_models_[i].append(instance)\n",
    "        instance.fit(X[train_index], y[train_index])\n",
    "        y_pred = instance.predict(X[holdout_index])\n",
    "        out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "    self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    meta_features = \\\n",
    "     np.column_stack \\\n",
    "     ( [ np.column_stack\n",
    "         ( [ model.predict(X) for model in base_models ] )\n",
    "         .mean(axis=1)\n",
    "         for base_models in self.base_models_ ] )\n",
    "    return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels \\\n",
    " ( base_models=(ENet, GBoost, KRR)\n",
    " , meta_model=lasso )\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print( 'Stacking Averaged models score: {:.4f} ({:.4f})'\n",
    "       .format( score.mean(), score.std() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "  return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.fit(train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \\\n",
    "( rmsle \\\n",
    "  ( y_train\n",
    "  ,   stacked_train_pred*0.70\n",
    "    + xgb_train_pred*0.15\n",
    "    + lgb_train_pred*0.15 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = ensemble\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
